# ğŸ™ï¸ Voice-Encoding

This project is part of the **StreamLingo VoiceSync** initiative. It focuses on extracting, visualizing, clustering, and tagging speaker embeddings using audio files and pretrained models like **wav2vec2**, **OpenL3**, and **VGGish**.

---

## ğŸ“Œ Objective

To analyze and compare speaker characteristics using voice embeddings and enable real-time features such as clustering, voice similarity search, and tagging support.

---

## ğŸ§  Models Used

| Model     | Dimensionality | Source       |
|-----------|----------------|--------------|
| wav2vec2  | 768            | Facebook AI  |
| OpenL3    | 512            | MIT CSAIL    |
| VGGish    | 128            | Google       |

---

## ğŸš€ Features Implemented

- âœ… Load and compare voice embeddings from `.npy` files  
- âœ… UMAP projection for dimensionality reduction  
- âœ… KMeans and HDBSCAN clustering  
- âœ… Cluster centroid generation  
- âœ… Voice similarity search using cosine similarity  
- âœ… Streamlit-based UI to explore embeddings  
- âœ… Audio tagging and metadata editor  
- âœ… (Experimental) Auto-tagging for:
  - Gender classification
  - Emotion classification (WIP)

---

## ğŸ–¼ Sample Outputs

- UMAP Projections  
- Cluster visualizations (KMeans, HDBSCAN)  
- Table mapping each audio to cluster  
- Centroid audio preview (prototype)  
- Similar voice results  
- Editable metadata tags

---

## ğŸ§­ Folder Structure

